{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6cec7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>year</th>\n",
       "      <th>met_gala_year</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iWS3oVeyjL4</td>\n",
       "      <td>upppp ice ate monocl</td>\n",
       "      <td>@HippiesHealingApothecary</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iWS3oVeyjL4</td>\n",
       "      <td>spoken conect scream well deep perhap everi qu...</td>\n",
       "      <td>@lotsofinterests</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iWS3oVeyjL4</td>\n",
       "      <td>feel dear cours harri hair assign wouldv becom...</td>\n",
       "      <td>@SeventhGate008</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.9274</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iWS3oVeyjL4</td>\n",
       "      <td>photographi excel hat kojo highlight der remin...</td>\n",
       "      <td>@shortourt14</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iWS3oVeyjL4</td>\n",
       "      <td>american anyway histori narrat comedi unlik af...</td>\n",
       "      <td>@KindnessKillsNONDO</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-14</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                               text  \\\n",
       "0  iWS3oVeyjL4                               upppp ice ate monocl   \n",
       "1  iWS3oVeyjL4  spoken conect scream well deep perhap everi qu...   \n",
       "2  iWS3oVeyjL4  feel dear cours harri hair assign wouldv becom...   \n",
       "3  iWS3oVeyjL4  photographi excel hat kojo highlight der remin...   \n",
       "4  iWS3oVeyjL4  american anyway histori narrat comedi unlik af...   \n",
       "\n",
       "                      author  likes        date      time  year  \\\n",
       "0  @HippiesHealingApothecary      0  2025-05-15  12:00:00  2025   \n",
       "1           @lotsofinterests      0  2025-05-15  06:00:00  2025   \n",
       "2            @SeventhGate008      0  2025-05-15  03:00:00  2025   \n",
       "3               @shortourt14      0  2025-05-15  01:00:00  2025   \n",
       "4        @KindnessKillsNONDO      0  2025-05-14  17:00:00  2025   \n",
       "\n",
       "   met_gala_year  sentiment  dominant_topic  \n",
       "0           2025     0.6124               4  \n",
       "1           2025     0.8689              13  \n",
       "2           2025     0.9274               5  \n",
       "3           2025     0.6597               5  \n",
       "4           2025     0.7845              14  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "# import the csv file.\n",
    "youtube_df = pd.read_csv('../../datasets/processed/youtube_comments_with_topics.csv')\n",
    "\n",
    "# check is imported.\n",
    "youtube_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing Met Gala Year: 2021\n",
      "==================================================\n",
      "Total comments in 2021: 13,370\n",
      "Unique videos in 2021: 4\n",
      "Unique commenters in 2021: 10,331\n",
      "Processing video ZMrgtotgThk: 9092 comments\n",
      "Processing video mrFfGptVzrI: 2167 comments\n",
      "Processing video qEvQa6xayYE: 2087 comments\n",
      "Processing video qKYhgn1TiV4: 24 comments\n",
      "\n",
      "Year 2021 Network Summary:\n",
      "  Nodes (commenters): 10,331\n",
      "  Edges (commenter connections): 28,047,904\n",
      "  Average comments per commenter: 1.29\n",
      "  Average videos per commenter: 1.01\n",
      "  Average shared videos per connection: 1.00\n",
      "  Most connected commenter: @dianemoonstone4715 (10312 connections)\n",
      "\n",
      "==================================================\n",
      "Processing Met Gala Year: 2022\n",
      "==================================================\n",
      "Total comments in 2022: 13,220\n",
      "Unique videos in 2022: 4\n",
      "Unique commenters in 2022: 10,569\n",
      "Processing video PbRZcvVnF0w: 6749 comments\n",
      "Processing video ItZ4SlxpOiI: 2153 comments\n",
      "Processing video lyJqXb8Nj-I: 1935 comments\n",
      "Processing video cpFc1RPOF7s: 2383 comments\n",
      "\n",
      "Year 2022 Network Summary:\n",
      "  Nodes (commenters): 10,569\n",
      "  Edges (commenter connections): 19,027,186\n",
      "  Average comments per commenter: 1.25\n",
      "  Average videos per commenter: 1.03\n",
      "  Average shared videos per connection: 1.00\n",
      "  Most connected commenter: @Xavierpng (10568 connections)\n",
      "\n",
      "==================================================\n",
      "Processing Met Gala Year: 2023\n",
      "==================================================\n",
      "Total comments in 2023: 7,168\n",
      "Unique videos in 2023: 3\n",
      "Unique commenters in 2023: 3,820\n",
      "Processing video E_WcvAiKQfI: 2439 comments\n",
      "Processing video XUIB4oWw37I: 689 comments\n",
      "Processing video LHCTW4pckDo: 4040 comments\n",
      "\n",
      "Year 2023 Network Summary:\n",
      "  Nodes (commenters): 3,820\n",
      "  Edges (commenter connections): 3,027,172\n",
      "  Average comments per commenter: 1.88\n",
      "  Average videos per commenter: 1.03\n",
      "  Average shared videos per connection: 1.00\n",
      "  Most connected commenter: @1111zeus (3819 connections)\n",
      "\n",
      "==================================================\n",
      "Processing Met Gala Year: 2024\n",
      "==================================================\n",
      "Total comments in 2024: 15,544\n",
      "Unique videos in 2024: 5\n",
      "Unique commenters in 2024: 12,330\n",
      "Processing video P71sr0kZY7o: 5891 comments\n",
      "Processing video JGVq7J5_sTk: 3349 comments\n",
      "Processing video jlR-T42I18E: 3444 comments\n",
      "Processing video urdBX1l0I6I: 1228 comments\n",
      "Processing video RqYRTmpBu0k: 1632 comments\n",
      "\n",
      "Year 2024 Network Summary:\n",
      "  Nodes (commenters): 12,330\n",
      "  Edges (commenter connections): 19,639,025\n",
      "  Average comments per commenter: 1.26\n",
      "  Average videos per commenter: 1.01\n",
      "  Average shared videos per connection: 1.00\n",
      "  Most connected commenter: @loro3849 (10186 connections)\n",
      "\n",
      "==================================================\n",
      "Processing Met Gala Year: 2025\n",
      "==================================================\n",
      "Total comments in 2025: 20,478\n",
      "Unique videos in 2025: 6\n",
      "Unique commenters in 2025: 16,475\n",
      "Processing video iWS3oVeyjL4: 3502 comments\n",
      "Processing video Ar9NFhmSnrk: 1737 comments\n",
      "Processing video YMPPo7APaoA: 314 comments\n",
      "Processing video NW2oiPiqByk: 9297 comments\n",
      "Processing video AyFzKATCiv0: 4694 comments\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# create a directed graph.\n",
    "def create_directed_graph(df: pd.DataFrame) -> nx.DiGraph:\n",
    "\n",
    "    graph = nx.DiGraph()\n",
    "\n",
    "    # for data in df.iterrows():\n",
    "\n",
    "yearly_graphs = {}  # Store graphs for each year\n",
    "yearly_video_commenter_data = {}  # Store video-commenter mapping for each year\n",
    "\n",
    "# Get unique years and sort them\n",
    "years = sorted(youtube_df['met_gala_year'].unique())\n",
    "\n",
    "# Loop through each year\n",
    "for year in years:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing Met Gala Year: {year}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Filter data for current year\n",
    "    year_data = youtube_df[youtube_df['met_gala_year'] == year].copy()\n",
    "    \n",
    "    print(f\"Total comments in {year}: {len(year_data):,}\")\n",
    "    print(f\"Unique videos in {year}: {year_data['video_id'].nunique():,}\")\n",
    "    print(f\"Unique commenters in {year}: {year_data['author'].nunique():,}\")\n",
    "    \n",
    "    # Initialize graph for this year\n",
    "    commenterGraph = nx.Graph()\n",
    "    \n",
    "    # Dictionary to store video_id -> {commenter_id: commenter_name, ...}\n",
    "    dVideoCommenters = {}\n",
    "    \n",
    "    # Get unique videos for this year\n",
    "    unique_videos = year_data['video_id'].unique()\n",
    "    \n",
    "    # Loop through each video in this year\n",
    "    for video_id in unique_videos:\n",
    "        \n",
    "        # Get all comments for this video\n",
    "        video_comments = year_data[year_data['video_id'] == video_id]\n",
    "        \n",
    "        print(f\"Processing video {video_id}: {len(video_comments)} comments\")\n",
    "        \n",
    "        # Initialize dictionary for this video\n",
    "        dVideoCommenters[video_id] = {}\n",
    "        \n",
    "        # Loop through each comment on this video\n",
    "        for idx, comment_row in video_comments.iterrows():\n",
    "            commenter = comment_row['author']\n",
    "            \n",
    "            # Skip if commenter is null or invalid\n",
    "            if pd.isna(commenter) or commenter == 'ExternalUserError' or commenter == '':\n",
    "                continue\n",
    "            \n",
    "            # Check if commenter is already in the graph for this year\n",
    "            # If so, update their comment count\n",
    "            # If not, create a new node with 1 comment\n",
    "            if commenter in commenterGraph:\n",
    "                commenterGraph.nodes[commenter]['commentNum'] += 1\n",
    "            else:\n",
    "                commenterGraph.add_node(commenter, commentNum=1, videosCommentedOn=set())\n",
    "            \n",
    "            # Add this video to the set of videos this commenter has commented on\n",
    "            commenterGraph.nodes[commenter]['videosCommentedOn'].add(video_id)\n",
    "            \n",
    "            # Store commenter for this video\n",
    "            dVideoCommenters[video_id][commenter] = commenter\n",
    "        \n",
    "        # Now create edges between all commenters who commented on this video\n",
    "        commenters_on_video = list(dVideoCommenters[video_id].keys())\n",
    "        \n",
    "        # For each pair of commenters on this video, create/update an edge\n",
    "        for i, commenter1 in enumerate(commenters_on_video):\n",
    "            for j, commenter2 in enumerate(commenters_on_video):\n",
    "                if i >= j:  # Avoid self-loops and duplicate edges\n",
    "                    continue\n",
    "                \n",
    "                # Check if edge already exists between these commenters\n",
    "                if commenterGraph.has_edge(commenter1, commenter2):\n",
    "                    # Increment the number of shared videos\n",
    "                    commenterGraph[commenter1][commenter2]['sharedVideos'] += 1\n",
    "                    commenterGraph[commenter1][commenter2]['videoList'].append(video_id)\n",
    "                else:\n",
    "                    # Need to check if both nodes exist (they should, but safety check)\n",
    "                    if commenter1 not in commenterGraph:\n",
    "                        commenterGraph.add_node(commenter1, commentNum=0, videosCommentedOn=set())\n",
    "                    if commenter2 not in commenterGraph:\n",
    "                        commenterGraph.add_node(commenter2, commentNum=0, videosCommentedOn=set())\n",
    "                    \n",
    "                    # Add new edge with shared video count = 1\n",
    "                    commenterGraph.add_edge(commenter1, commenter2, \n",
    "                                          sharedVideos=1, \n",
    "                                          videoList=[video_id])\n",
    "    \n",
    "    # Convert videosCommentedOn sets to counts for storage\n",
    "    for node in commenterGraph.nodes():\n",
    "        commenterGraph.nodes[node]['uniqueVideosCount'] = len(commenterGraph.nodes[node]['videosCommentedOn'])\n",
    "        # Convert set to list for JSON serialization if needed later\n",
    "        commenterGraph.nodes[node]['videosCommentedOn'] = list(commenterGraph.nodes[node]['videosCommentedOn'])\n",
    "    \n",
    "    # Store results for this year\n",
    "    yearly_graphs[year] = commenterGraph\n",
    "    yearly_video_commenter_data[year] = dVideoCommenters\n",
    "    \n",
    "    # Print summary statistics for this year\n",
    "    print(f\"\\nYear {year} Network Summary:\")\n",
    "    print(f\"  Nodes (commenters): {commenterGraph.number_of_nodes():,}\")\n",
    "    print(f\"  Edges (commenter connections): {commenterGraph.number_of_edges():,}\")\n",
    "    \n",
    "    # Calculate some interesting statistics\n",
    "    if commenterGraph.number_of_nodes() > 0:\n",
    "        # Average comments per commenter\n",
    "        avg_comments = sum(data['commentNum'] for node, data in commenterGraph.nodes(data=True)) / commenterGraph.number_of_nodes()\n",
    "        print(f\"  Average comments per commenter: {avg_comments:.2f}\")\n",
    "        \n",
    "        # Average videos per commenter\n",
    "        avg_videos = sum(data['uniqueVideosCount'] for node, data in commenterGraph.nodes(data=True)) / commenterGraph.number_of_nodes()\n",
    "        print(f\"  Average videos per commenter: {avg_videos:.2f}\")\n",
    "        \n",
    "        if commenterGraph.number_of_edges() > 0:\n",
    "            # Average shared videos per connection\n",
    "            avg_shared = sum(data['sharedVideos'] for u, v, data in commenterGraph.edges(data=True)) / commenterGraph.number_of_edges()\n",
    "            print(f\"  Average shared videos per connection: {avg_shared:.2f}\")\n",
    "            \n",
    "            # Most connected commenter\n",
    "            degrees = dict(commenterGraph.degree())\n",
    "            most_connected = max(degrees, key=degrees.get)\n",
    "            print(f\"  Most connected commenter: {most_connected} ({degrees[most_connected]} connections)\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"OVERALL SUMMARY:\")\n",
    "print(f\"{'='*60}\")\n",
    "for year in years:\n",
    "    graph = yearly_graphs[year]\n",
    "    print(f\"Year {year}: {graph.number_of_nodes():,} commenters, {graph.number_of_edges():,} connections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a670c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Processing Met Gala Year: 2021\n",
      "========================================\n",
      "Total videos in 2021: 13,370\n",
      "Unique authors in 2021: 10,331\n",
      "Average videos per commenter: 1.3\n",
      "Large dataset detected. Sampling 5000 videos for faster processing...\n",
      "Using 5000 sampled videos\n",
      "          video_id                                               text  \\\n",
      "58429  ZMrgtotgThk  work rich task pretend american class wear wel...   \n",
      "66098  mrFfGptVzrI                              talkin nobodi madison   \n",
      "61635  ZMrgtotgThk  either sort @josephinegodin9079 statu there' l...   \n",
      "60002  ZMrgtotgThk  river never child fearless blackwel luke opini...   \n",
      "63232  ZMrgtotgThk  research hautelemod interview articl lol guess...   \n",
      "\n",
      "                  author  likes        date      time  year  met_gala_year  \\\n",
      "58429   @aquariusjewelry      0  2022-05-15  17:00:00  2022           2021   \n",
      "66098    @madslivtxt3685      0  2022-05-15  17:00:00  2022           2021   \n",
      "61635      @ElizabethT45      0  2022-05-15  17:00:00  2022           2021   \n",
      "60002  @danielclaeys7598      0  2022-05-15  17:00:00  2022           2021   \n",
      "63232        @SadBugBleu      0  2022-05-15  17:00:00  2022           2021   \n",
      "\n",
      "       sentiment  dominant_topic  \n",
      "58429     0.6486               2  \n",
      "66098     0.0000              13  \n",
      "61635     0.2263               1  \n",
      "60002     0.0243               7  \n",
      "63232     0.4215               8  \n",
      "\n",
      "========================================\n",
      "Processing Met Gala Year: 2022\n",
      "========================================\n",
      "Total videos in 2022: 13,220\n",
      "Unique authors in 2022: 10,569\n",
      "Average videos per commenter: 1.3\n",
      "Large dataset detected. Sampling 5000 videos for faster processing...\n",
      "Using 5000 sampled videos\n",
      "          video_id                                               text  \\\n",
      "54679  cpFc1RPOF7s             question instead @theduckarmy12 answer   \n",
      "46568  PbRZcvVnF0w  room wait cant worth skin famili bad secret wa...   \n",
      "55075  cpFc1RPOF7s                                      lord man fine   \n",
      "52445  lyJqXb8Nj-I                                               song   \n",
      "51864  ItZ4SlxpOiI  bring glad emma serious say lol liter best hop...   \n",
      "\n",
      "               author  likes        date      time  year  met_gala_year  \\\n",
      "54679  @grigorecosmin      0  2022-05-15  17:00:00  2022           2022   \n",
      "46568     @ixsweetpea      0  2022-05-15  17:00:00  2022           2022   \n",
      "55075       @ThePuff_      0  2022-05-15  17:00:00  2022           2022   \n",
      "52445   @rebecapl9953      0  2022-05-15  17:00:00  2022           2022   \n",
      "51864  @orangespiderz      0  2022-05-15  17:00:00  2022           2022   \n",
      "\n",
      "       sentiment  dominant_topic  \n",
      "54679     0.0000              13  \n",
      "46568     0.0346               4  \n",
      "55075     0.2023               3  \n",
      "52445     0.0000               4  \n",
      "51864     0.9118              13  \n",
      "\n",
      "========================================\n",
      "Processing Met Gala Year: 2023\n",
      "========================================\n",
      "Total videos in 2023: 7,168\n",
      "Unique authors in 2023: 3,820\n",
      "Average videos per commenter: 1.9\n",
      "Large dataset detected. Sampling 5000 videos for faster processing...\n",
      "Using 5000 sampled videos\n",
      "          video_id                                               text  \\\n",
      "42933  LHCTW4pckDo                                              guess   \n",
      "36479  E_WcvAiKQfI                            next pleas horror theme   \n",
      "42926  LHCTW4pckDo                                              invit   \n",
      "37671  E_WcvAiKQfI  hate brand bad outfit mayb chanel fendi fur tacki   \n",
      "38914  XUIB4oWw37I       appar readi design michel dress say karl met   \n",
      "\n",
      "                          author  likes        date      time  year  \\\n",
      "42933           @angelicabirata0      0  2024-05-15  17:00:00  2024   \n",
      "36479     @EmmanuelChinedu-or4zu      0  2023-05-15  17:00:00  2023   \n",
      "42926          @mikedemarb-wq7dh      0  2023-05-15  17:00:00  2023   \n",
      "37671                    @en2186      0  2023-05-15  17:00:00  2023   \n",
      "38914  @guillermoturellyarur4699      0  2023-05-15  17:00:00  2023   \n",
      "\n",
      "       met_gala_year  sentiment  dominant_topic  \n",
      "42933           2023     0.0000               8  \n",
      "36479           2023    -0.5719               9  \n",
      "42926           2023     0.0000               4  \n",
      "37671           2023    -0.8020              11  \n",
      "38914           2023     0.0000               3  \n",
      "\n",
      "========================================\n",
      "Processing Met Gala Year: 2024\n",
      "========================================\n",
      "Total videos in 2024: 15,544\n",
      "Unique authors in 2024: 12,330\n",
      "Average videos per commenter: 1.3\n",
      "Large dataset detected. Sampling 5000 videos for faster processing...\n",
      "Using 5000 sampled videos\n",
      "          video_id                                               text  \\\n",
      "24876  P71sr0kZY7o                             money better drag race   \n",
      "26465  JGVq7J5_sTk                               middl east oasi base   \n",
      "33122  jlR-T42I18E                                 @sambatra6162 haha   \n",
      "32342  jlR-T42I18E                               done dress stun well   \n",
      "30377  jlR-T42I18E  mmm beauti american independ stun fair theme f...   \n",
      "\n",
      "                     author  likes        date      time  year  met_gala_year  \\\n",
      "24876     @davidkonevky7372      0  2024-05-15  17:00:00  2024           2024   \n",
      "26465   @MaryMuscarella-v7p      0  2025-04-15  17:00:00  2025           2024   \n",
      "33122             @saorcali      0  2022-05-15  17:00:00  2022           2024   \n",
      "32342  @fashionablylate9020      0  2022-05-15  17:00:00  2022           2024   \n",
      "30377      @annemacleod1421      0  2022-05-15  17:00:00  2022           2024   \n",
      "\n",
      "       sentiment  dominant_topic  \n",
      "24876     0.2500               6  \n",
      "26465     0.0000              13  \n",
      "33122     0.4588               5  \n",
      "32342     0.2732              10  \n",
      "30377     0.7845               3  \n",
      "\n",
      "========================================\n",
      "Processing Met Gala Year: 2025\n",
      "========================================\n",
      "Total videos in 2025: 20,478\n",
      "Unique authors in 2025: 16,475\n",
      "Average videos per commenter: 1.2\n",
      "Large dataset detected. Sampling 5000 videos for faster processing...\n",
      "Using 5000 sampled videos\n",
      "          video_id                    text          author  likes        date  \\\n",
      "15258  AyFzKATCiv0           jealou aezzzx         @Isir-M      0  2025-05-09   \n",
      "20156  BbAgK_jGRfE             mindi shank    @laurapotpie      0  2025-05-07   \n",
      "6812   NW2oiPiqByk   share thank lot learn  @StaieWaltraud      0  2025-05-08   \n",
      "10056  NW2oiPiqByk  hour minut googl learn        @溫林維-i6i      0  2025-05-07   \n",
      "8142   NW2oiPiqByk              day repeat    @mrrakib-s3n      0  2025-05-07   \n",
      "\n",
      "           time  year  met_gala_year  sentiment  dominant_topic  \n",
      "15258  17:00:00  2025           2025     0.0000               1  \n",
      "20156  17:00:00  2025           2025     0.0000               1  \n",
      "6812   17:00:00  2025           2025     0.5719              12  \n",
      "10056  17:00:00  2025           2025     0.0000              12  \n",
      "8142   17:00:00  2025           2025     0.0000               7  \n"
     ]
    }
   ],
   "source": [
    "# get all years in csv for loop to create directed community graphs based off the year of the met gala.\n",
    "years = sorted(youtube_df['met_gala_year'].unique())\n",
    "results = {}\n",
    "\n",
    "for year in years:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Processing Met Gala Year: {year}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # filter data for current year - THIS GETS ALL ROWS FOR THE YEAR.\n",
    "    year_data = youtube_df[youtube_df['met_gala_year'] == year].copy()\n",
    "    \n",
    "    print(f\"Total videos in {year}: {len(year_data):,}\")  # comma formatting for large numbers.\n",
    "    print(f\"Unique authors in {year}: {year_data['author'].nunique():,}\")\n",
    "    print(f\"Average videos per commenter: {len(year_data) / year_data['author'].nunique():.1f}\")\n",
    "    \n",
    "    # For very large datasets, sample an amount of data  to check code is working.\n",
    "    # COMMENT OUT WHEN RUNNING FOR REAL RESULTS.\n",
    "    if len(year_data) > 5000:\n",
    "        year_data = year_data.sample(n=5000, random_state=42)\n",
    "\n",
    "    year_directed_graph = create_directed_graph(year_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d6b1be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subreddit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# loop through the hot submissions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m submission \u001b[38;5;129;01min\u001b[39;00m subreddit\u001b[38;5;241m.\u001b[39mhot(limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# check if author name is in the reply graph - if so, we update the number of submissions\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# associated with this user\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# if not, we construct a new node with 1 associated submission\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m submission\u001b[38;5;241m.\u001b[39mauthor\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m replyGraph:\n\u001b[1;32m      8\u001b[0m         replyGraph\u001b[38;5;241m.\u001b[39mnodes[submission\u001b[38;5;241m.\u001b[39mauthor\u001b[38;5;241m.\u001b[39mname][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubNum\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subreddit' is not defined"
     ]
    }
   ],
   "source": [
    "# loop through the hot submissions\n",
    "for submission in subreddit.hot(limit=20):\n",
    "    \n",
    "    # check if author name is in the reply graph - if so, we update the number of submissions\n",
    "    # associated with this user\n",
    "    # if not, we construct a new node with 1 associated submission\n",
    "    if submission.author.name in replyGraph:\n",
    "        replyGraph.nodes[submission.author.name]['subNum'] += 1\n",
    "    else:\n",
    "        replyGraph.add_node(submission.author.name, subNum=1)\n",
    "\n",
    "    submissionId = submission.name;\n",
    "    # this stores the submissionId (in submission.name) and associate it to the author\n",
    "    # (submission.author.name).\n",
    "    dSubCommentId[submissionId] = {submissionId : submission.author.name}\n",
    "\n",
    "    # for the current submission, retrieve the associated comments\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    for comment in submission.comments.list():\n",
    "\n",
    "        # some data checking to cater for deleted comments\n",
    "        # we only add a link if the comment hasn't been deleted\n",
    "        if comment.author is not None and comment.author.name != 'ExternalUserError':\n",
    "            dSubCommentId[submissionId].update({comment.name : comment.author.name})\n",
    "\n",
    "            # check if we have seen the comment's parent yet.  If not, then parent comment has been\n",
    "            # deleted\n",
    "            if comment.parent_id in dSubCommentId[submissionId]:\n",
    "                # if edge exists, increment the replyNum, otherwise add a new edge\n",
    "                if replyGraph.has_edge(comment.author.name, dSubCommentId[submissionId][comment.parent_id]):\n",
    "                    replyGraph[comment.author.name][dSubCommentId[submissionId][comment.parent_id]]['replyNum'] += 1\n",
    "                else:\n",
    "                    # need to check if the nodes have been added yet, if not add it and set subNum to 0\n",
    "                    if not comment.author.name in replyGraph:\n",
    "                        replyGraph.add_node(comment.author.name, subNum=0)\n",
    "\n",
    "                    if not dSubCommentId[submissionId][comment.parent_id] in replyGraph:\n",
    "                        replyGraph.add_node(dSubCommentId[submissionId][comment.parent_id], subNum=0)\n",
    "\n",
    "                    replyGraph.add_edge(comment.author.name, dSubCommentId[submissionId][comment.parent_id], replyNum=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
