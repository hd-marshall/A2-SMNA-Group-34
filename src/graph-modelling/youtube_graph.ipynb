{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6cec7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>2021</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A$AP Rocky</td>\n",
       "      <td>2021</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rihanna</td>\n",
       "      <td>2021</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jennifer Lopez</td>\n",
       "      <td>2021</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lil Nas X</td>\n",
       "      <td>2021</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  Year   Gender\n",
       "0   Billie Eilish  2021  Unknown\n",
       "1      A$AP Rocky  2021     Male\n",
       "2         Rihanna  2021   Female\n",
       "3  Jennifer Lopez  2021   Female\n",
       "4       Lil Nas X  2021     Male"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "# import the celeb csv file.\n",
    "comments_df = pd.read_csv('../../datasets/raw/youtube_comments.csv')\n",
    "\n",
    "# import celeb csv file.\n",
    "celeb_df = pd.read_csv(\"../../datasets/attendees.csv\")\n",
    "\n",
    "# check is imported.\n",
    "comments_df.head(5)\n",
    "celeb_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee2026e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'attendees.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict, Counter\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# --- Step 1: Load data and create celebrity-year mapping ---\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m celeb_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattendees.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Replace with your actual filename\u001b[39;00m\n\u001b[1;32m     13\u001b[0m comments_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_youtube_comments.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Replace with your actual filename\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttendees CSV columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(celeb_df\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'attendees.csv'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "print(f\"Attendees CSV columns: {list(celeb_df.columns)}\")\n",
    "print(f\"Comments CSV columns: {list(comments_df.columns)}\")\n",
    "\n",
    "# --- Step 2: Text preprocessing function (for celebrity names only) ---\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess celebrity names for better matching with already-preprocessed comments\"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove extra whitespace and normalize\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove common punctuation that might interfere with name matching\n",
    "    text = re.sub(r'[^\\w\\s\\'-]', ' ', text)\n",
    "    \n",
    "    # Handle common variations\n",
    "    text = re.sub(r'\\bkim\\s*k\\b', 'kim kardashian', text)\n",
    "    text = re.sub(r'\\bkardashian\\b', 'kim kardashian', text)  \n",
    "    text = re.sub(r'\\bzendaya\\b', 'zendaya', text)\n",
    "    text = re.sub(r'\\btaylor\\s*swift\\b', 'taylor swift', text)\n",
    "    text = re.sub(r'\\bt\\s*swift\\b', 'taylor swift', text)\n",
    "    text = re.sub(r'\\bbeyonce\\b', 'beyonce', text)\n",
    "    text = re.sub(r'\\bbey\\b', 'beyonce', text)\n",
    "    text = re.sub(r'\\bjlo\\b', 'jennifer lopez', text)\n",
    "    text = re.sub(r'\\bj\\s*lo\\b', 'jennifer lopez', text)\n",
    "    text = re.sub(r'\\bariana\\b', 'ariana grande', text)\n",
    "    text = re.sub(r'\\bari\\b', 'ariana grande', text)\n",
    "    text = re.sub(r'\\bselena\\b', 'selena gomez', text)\n",
    "    text = re.sub(r'\\briri\\b', 'rihanna', text)\n",
    "    text = re.sub(r'\\bgaga\\b', 'lady gaga', text)\n",
    "    text = re.sub(r'\\blady\\s*gaga\\b', 'lady gaga', text)\n",
    "    text = re.sub(r'\\bdua\\b', 'dua lipa', text)\n",
    "    text = re.sub(r'\\bbillie\\b', 'billie eilish', text)\n",
    "    text = re.sub(r'\\bthe\\s*weeknd\\b', 'the weeknd', text)\n",
    "    text = re.sub(r'\\bweeknd\\b', 'the weeknd', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Create mapping of celebrity -> years they attended\n",
    "# Only preprocess celebrity names, comments are already preprocessed\n",
    "celeb_year_mapping = {}\n",
    "for index, row in celeb_df.iterrows():\n",
    "    name = row.get('Name')\n",
    "    year = row.get('Year')  # Attendees CSV uses 'Year' column (capital Y)\n",
    "    \n",
    "    if pd.notna(name) and pd.notna(year):\n",
    "        processed_name = preprocess_text(name)  # Preprocess celebrity name to match preprocessed comments\n",
    "        if processed_name:\n",
    "            if processed_name not in celeb_year_mapping:\n",
    "                celeb_year_mapping[processed_name] = set()\n",
    "            celeb_year_mapping[processed_name].add(year)\n",
    "\n",
    "print(f\"\\nLoaded celebrity attendance data for {len(celeb_year_mapping)} celebrities:\")\n",
    "for celeb, years in list(celeb_year_mapping.items())[:10]:  # Show first 10 as example\n",
    "    print(f\"  {celeb}: {sorted(years)}\")\n",
    "if len(celeb_year_mapping) > 10:\n",
    "    print(f\"  ... and {len(celeb_year_mapping) - 10} more\")\n",
    "\n",
    "# --- Step 3: Setup celebrity patterns (full names only) ---\n",
    "raw_celeb_names = celeb_df['Name'].dropna().unique()\n",
    "\n",
    "# Create mapping system for full names only\n",
    "celeb_name_mapping = {}\n",
    "all_patterns = []\n",
    "\n",
    "for original_name in raw_celeb_names:\n",
    "    processed_name = preprocess_text(original_name)\n",
    "    if not processed_name:\n",
    "        continue\n",
    "    \n",
    "    # Store the canonical name (full name only)\n",
    "    canonical_name = processed_name\n",
    "    \n",
    "    # Add full name pattern only\n",
    "    celeb_name_mapping[processed_name] = canonical_name\n",
    "    all_patterns.append((processed_name, canonical_name, len(processed_name)))\n",
    "\n",
    "# Sort patterns by length (longest first) for better matching\n",
    "all_patterns.sort(key=lambda x: x[2], reverse=True)\n",
    "pattern_strings = [re.escape(pattern[0]) for pattern in all_patterns]\n",
    "\n",
    "celeb_regex = re.compile(r'\\b(?:' + '|'.join(pattern_strings) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "print(f\"Loaded {len(raw_celeb_names)} celebrity names\")\n",
    "print(f\"Created {len(pattern_strings)} search patterns (full names only)\")\n",
    "print(f\"Loaded {len(comments_df)} comments\")\n",
    "\n",
    "# --- Step 4: Create output directory and data collection structures ---\n",
    "output_dir = \"comention_graphs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Data collection structures for plotting\n",
    "celebrity_mentions_by_year = defaultdict(lambda: defaultdict(int))  # {year: {celebrity: count}}\n",
    "celebrity_mentions_overall = defaultdict(int)  # {celebrity: total_count}\n",
    "yearly_totals = defaultdict(int)  # {year: total_mentions}\n",
    "\n",
    "# --- Step 5: Function to extract celebrity mentions with year filtering ---\n",
    "def extract_mentions(text, comment_year):\n",
    "    \"\"\"Extract celebrity mentions from text (text is already preprocessed)\"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return []\n",
    "    \n",
    "    # Text is already preprocessed, use as-is\n",
    "    processed_text = str(text).lower()\n",
    "    \n",
    "    # Find all matches with their positions\n",
    "    matches = []\n",
    "    for match in celeb_regex.finditer(processed_text):\n",
    "        match_text = match.group().lower()\n",
    "        if match_text in celeb_name_mapping:\n",
    "            celebrity_name = celeb_name_mapping[match_text]\n",
    "            \n",
    "            # Only include if celebrity attended in this comment's year\n",
    "            if celebrity_name in celeb_year_mapping and comment_year in celeb_year_mapping[celebrity_name]:\n",
    "                matches.append((match.start(), match.end(), match_text, celebrity_name))\n",
    "    \n",
    "    # Remove overlapping matches (prefer longer matches)\n",
    "    matches.sort(key=lambda x: x[0])\n",
    "    \n",
    "    non_overlapping = []\n",
    "    for i, (start, end, match_text, canonical) in enumerate(matches):\n",
    "        # Check if this match overlaps with any previously accepted match\n",
    "        overlaps = False\n",
    "        for prev_start, prev_end, _, _ in non_overlapping:\n",
    "            if not (end <= prev_start or start >= prev_end):  # They overlap\n",
    "                overlaps = True\n",
    "                break\n",
    "        \n",
    "        if not overlaps:\n",
    "            non_overlapping.append((start, end, match_text, canonical))\n",
    "    \n",
    "    # Extract unique celebrity names (remove duplicates where same person mentioned multiple times)\n",
    "    celebrity_mentions = set()\n",
    "    for _, _, _, canonical in non_overlapping:\n",
    "        celebrity_mentions.add(canonical)\n",
    "    \n",
    "    return list(celebrity_mentions)\n",
    "\n",
    "# --- Step 6: Function to create co-mention graph and collect mention data ---\n",
    "def create_comention_graph(df, year_filter=None, collect_data=False):\n",
    "    \"\"\"Create co-mention graph for celebrities mentioned together and optionally collect mention data\"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Filter by year if specified\n",
    "    if year_filter:\n",
    "        df = df[df['met_gala_year'] == year_filter]\n",
    "        graph_name = f\"Met Gala {year_filter}\"\n",
    "    else:\n",
    "        graph_name = \"All Years\"\n",
    "    \n",
    "    print(f\"\\n=== Processing {graph_name} ===\")\n",
    "    print(f\"Processing {len(df)} comments...\")\n",
    "    \n",
    "    mention_count = 0\n",
    "    total_mentions = 0\n",
    "    \n",
    "    # Process each comment\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract text and year from the comment\n",
    "        comment_text = str(row.get('text', ''))\n",
    "        comment_year = row.get('met_gala_year')  # Extract the comment year!\n",
    "        \n",
    "        if pd.isna(comment_year):\n",
    "            continue\n",
    "        \n",
    "        # Find mentioned celebrities (filtered by year they attended)\n",
    "        mentioned = extract_mentions(comment_text, comment_year)\n",
    "        total_mentions += len(mentioned)\n",
    "        \n",
    "        # Collect data for plotting if requested\n",
    "        if collect_data:\n",
    "            for celebrity in mentioned:\n",
    "                celebrity_mentions_by_year[comment_year][celebrity] += 1\n",
    "                celebrity_mentions_overall[celebrity] += 1\n",
    "                yearly_totals[comment_year] += 1\n",
    "        \n",
    "        if len(mentioned) > 1:\n",
    "            mention_count += 1\n",
    "            # Create edges for all pairs of mentioned celebrities\n",
    "            for celeb1, celeb2 in combinations(sorted(mentioned), 2):\n",
    "                if G.has_edge(celeb1, celeb2):\n",
    "                    G[celeb1][celeb2]['weight'] += 1\n",
    "                else:\n",
    "                    G.add_edge(celeb1, celeb2, weight=1)\n",
    "    \n",
    "    return G, mention_count, total_mentions, graph_name\n",
    "\n",
    "# --- Step 7: Function to analyze graph ---\n",
    "def analyze_comention_graph(G, mention_count, total_mentions, graph_name, df_size):\n",
    "    \"\"\"Analyze and print co-mention graph statistics\"\"\"\n",
    "    print(f\"\\n=== {graph_name} Co-mention Graph Summary ===\")\n",
    "    print(f\"Total comments processed: {df_size}\")\n",
    "    print(f\"Total celebrity mentions: {total_mentions}\")\n",
    "    print(f\"Comments with multiple celebrity mentions: {mention_count}\")\n",
    "    print(f\"Nodes (Celebrities): {G.number_of_nodes()}\")\n",
    "    print(f\"Edges (Co-mentions): {G.number_of_edges()}\")\n",
    "    \n",
    "    if G.number_of_edges() == 0:\n",
    "        print(\"No co-mentions found for this period.\")\n",
    "        return\n",
    "    \n",
    "    # Top co-mentions\n",
    "    print(f\"\\n--- Top 10 Celebrity Co-mentions ({graph_name}) ---\")\n",
    "    edges_with_weights = [(u, v, data['weight']) for u, v, data in G.edges(data=True)]\n",
    "    edges_with_weights.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    for i, (celeb1, celeb2, weight) in enumerate(edges_with_weights[:10]):\n",
    "        print(f\"{i+1}. {celeb1.title()} & {celeb2.title()}: {weight} co-mentions\")\n",
    "    \n",
    "    # Most connected celebrities\n",
    "    print(f\"\\n--- Most Connected Celebrities ({graph_name}) ---\")\n",
    "    if G.number_of_nodes() > 0:\n",
    "        degrees = dict(G.degree())\n",
    "        sorted_degrees = sorted(degrees.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for i, (celeb, degree) in enumerate(sorted_degrees[:10]):\n",
    "            print(f\"{i+1}. {celeb.title()}: {degree} connections\")\n",
    "    \n",
    "    # Additional statistics\n",
    "    if G.number_of_nodes() > 0:\n",
    "        print(f\"\\n--- Network Statistics ({graph_name}) ---\")\n",
    "        print(f\"Average degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\")\n",
    "        \n",
    "        # Most frequently co-mentioned pairs\n",
    "        total_weight = sum([data['weight'] for u, v, data in G.edges(data=True)])\n",
    "        print(f\"Total co-mention instances: {total_weight}\")\n",
    "        \n",
    "        if G.number_of_edges() > 0:\n",
    "            avg_weight = total_weight / G.number_of_edges()\n",
    "            print(f\"Average co-mentions per pair: {avg_weight:.2f}\")\n",
    "\n",
    "# --- Step 8: Function to save graph ---\n",
    "def save_comention_graph(G, graph_name, year_filter=None):\n",
    "    \"\"\"Save co-mention graph as GraphML file\"\"\"\n",
    "    if year_filter:\n",
    "        filename = f\"celeb_comentions_{year_filter}.graphml\"\n",
    "    else:\n",
    "        filename = \"celeb_comentions_all_years.graphml\"\n",
    "    \n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    nx.write_graphml(G, filepath)\n",
    "    print(f\"Saved {graph_name} graph: {filepath}\")\n",
    "\n",
    "# --- Step 9: Create and analyze all-years graph (with data collection) ---\n",
    "G_all, mentions_all, total_mentions_all, name_all = create_comention_graph(comments_df, collect_data=True)\n",
    "analyze_comention_graph(G_all, mentions_all, total_mentions_all, name_all, len(comments_df))\n",
    "save_comention_graph(G_all, name_all)\n",
    "\n",
    "# --- Step 10: Create and analyze individual year graphs ---\n",
    "unique_years = sorted(comments_df['met_gala_year'].dropna().unique())\n",
    "print(f\"\\n=== Found {len(unique_years)} unique years: {unique_years} ===\")\n",
    "\n",
    "year_graphs = {}\n",
    "for year in unique_years:\n",
    "    year_df = comments_df[comments_df['met_gala_year'] == year]\n",
    "    G_year, mentions_year, total_mentions_year, name_year = create_comention_graph(comments_df, year)\n",
    "    \n",
    "    if G_year.number_of_nodes() > 0:  # Only analyze if graph has data\n",
    "        analyze_comention_graph(G_year, mentions_year, total_mentions_year, name_year, len(year_df))\n",
    "        save_comention_graph(G_year, name_year, year)\n",
    "        year_graphs[year] = G_year\n",
    "    else:\n",
    "        print(f\"No co-mentions found for {year}\")\n",
    "\n",
    "# --- Step 11: Cross-year comparison ---\n",
    "print(f\"\\n=== Cross-Year Co-mention Comparison ===\")\n",
    "for year in unique_years:\n",
    "    if year in year_graphs:\n",
    "        G = year_graphs[year]\n",
    "        total_weight = sum([data['weight'] for u, v, data in G.edges(data=True)])\n",
    "        print(f\"{year}: {G.number_of_nodes()} celebrities, {G.number_of_edges()} pairs, {total_weight} total co-mentions\")\n",
    "\n",
    "# --- Step 12: Most mentioned celebrities across all data (with year filtering) ---\n",
    "print(f\"\\n=== Most Mentioned Celebrities (All Years, Year-Filtered) ===\")\n",
    "all_celebrity_mentions = []\n",
    "for index, row in comments_df.iterrows():\n",
    "    comment_text = str(row.get('text', ''))\n",
    "    comment_year = row.get('met_gala_year')\n",
    "    \n",
    "    if pd.notna(comment_year):\n",
    "        mentioned = extract_mentions(comment_text, comment_year)\n",
    "        all_celebrity_mentions.extend(mentioned)\n",
    "\n",
    "if all_celebrity_mentions:\n",
    "    mention_counts = Counter(all_celebrity_mentions)\n",
    "    \n",
    "    for i, (celeb, count) in enumerate(mention_counts.most_common(15)):\n",
    "        # Show which years this celebrity attended\n",
    "        years_attended = sorted(celeb_year_mapping.get(celeb, []))\n",
    "        print(f\"{i+1}. {celeb.title()}: mentioned {count} times (attended: {years_attended})\")\n",
    "else:\n",
    "    print(\"No valid celebrity mentions found after year filtering\")\n",
    "\n",
    "# --- Step 13: Year-specific mention analysis ---\n",
    "print(f\"\\n=== Celebrity Mentions by Year ===\")\n",
    "for year in unique_years:\n",
    "    year_comments = comments_df[comments_df['met_gala_year'] == year]\n",
    "    year_mentions = []\n",
    "    \n",
    "    for index, row in year_comments.iterrows():\n",
    "        comment_text = str(row.get('text', ''))\n",
    "        comment_year = row.get('met_gala_year')\n",
    "        if pd.notna(comment_year):\n",
    "            mentioned = extract_mentions(comment_text, comment_year)\n",
    "            year_mentions.extend(mentioned)\n",
    "    \n",
    "    if year_mentions:\n",
    "        year_counts = Counter(year_mentions)\n",
    "        print(f\"\\n{year} - Top mentioned celebrities:\")\n",
    "        for i, (celeb, count) in enumerate(year_counts.most_common(5)):\n",
    "            print(f\"  {i+1}. {celeb.title()}: {count} mentions\")\n",
    "    else:\n",
    "        print(f\"\\n{year} - No valid celebrity mentions found\")\n",
    "\n",
    "# --- Step 14: Create simplified blue bar chart visualizations ---\n",
    "def create_celebrity_mention_plots():\n",
    "    \"\"\"Create blue bar charts showing top celebrity mentions for each year\"\"\"\n",
    "    print(f\"\\n=== Creating Celebrity Mention Bar Charts ===\")\n",
    "    \n",
    "    # Set up the plotting style\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    # Years to analyze\n",
    "    years_to_plot = [2021, 2022, 2023, 2024, 2025]\n",
    "    \n",
    "    # Create individual year plots\n",
    "    for year in years_to_plot:\n",
    "        if year in celebrity_mentions_by_year and len(celebrity_mentions_by_year[year]) > 0:\n",
    "            # Get top 15 celebrities for this year\n",
    "            year_data = dict(celebrity_mentions_by_year[year])\n",
    "            top_celebs = dict(Counter(year_data).most_common(15))\n",
    "            \n",
    "            if len(top_celebs) > 0:\n",
    "                # Create figure\n",
    "                fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                \n",
    "                celeb_names = [name.title() for name in top_celebs.keys()]\n",
    "                mention_counts = list(top_celebs.values())\n",
    "                \n",
    "                # Create horizontal bar chart in blue\n",
    "                bars = ax.barh(celeb_names, mention_counts, color='#1f77b4', alpha=0.8)\n",
    "                \n",
    "                ax.set_xlabel('Number of Mentions', fontsize=12, fontweight='bold')\n",
    "                ax.set_ylabel('Celebrity', fontsize=12, fontweight='bold')\n",
    "                ax.set_title(f'Top Celebrity Mentions - Met Gala {year}', fontsize=16, fontweight='bold')\n",
    "                ax.grid(axis='x', alpha=0.3)\n",
    "                \n",
    "                # Add value labels on bars\n",
    "                for bar, count in zip(bars, mention_counts):\n",
    "                    ax.text(bar.get_width() + max(mention_counts) * 0.01, \n",
    "                           bar.get_y() + bar.get_height()/2, \n",
    "                           str(count), ha='left', va='center', fontweight='bold')\n",
    "                \n",
    "                # Adjust layout\n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Save the plot\n",
    "                plot_path = os.path.join(output_dir, f'celebrity_mentions_{year}.png')\n",
    "                plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "                print(f\"Saved {year} celebrity mentions chart: {plot_path}\")\n",
    "                \n",
    "                plt.show()\n",
    "                plt.close()\n",
    "            else:\n",
    "                print(f\"No celebrity mention data found for {year}\")\n",
    "        else:\n",
    "            print(f\"No data available for {year}\")\n",
    "    \n",
    "    # Create overall chart (all years combined)\n",
    "    if len(celebrity_mentions_overall) > 0:\n",
    "        # Get top 15 celebrities overall\n",
    "        top_celebs_overall = dict(Counter(celebrity_mentions_overall).most_common(15))\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        celeb_names = [name.title() for name in top_celebs_overall.keys()]\n",
    "        mention_counts = list(top_celebs_overall.values())\n",
    "        \n",
    "        # Create horizontal bar chart in blue\n",
    "        bars = ax.barh(celeb_names, mention_counts, color='#1f77b4', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Number of Mentions', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Celebrity', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Top Celebrity Mentions - All Years (2021-2025)', fontsize=16, fontweight='bold')\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, count in zip(bars, mention_counts):\n",
    "            ax.text(bar.get_width() + max(mention_counts) * 0.01, \n",
    "                   bar.get_y() + bar.get_height()/2, \n",
    "                   str(count), ha='left', va='center', fontweight='bold')\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        plot_path = os.path.join(output_dir, 'celebrity_mentions_all_years.png')\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved all years celebrity mentions chart: {plot_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    # Show summary\n",
    "    print(f\"\\n--- Summary ---\")\n",
    "    print(f\"Created blue bar charts for celebrity mentions:\")\n",
    "    for year in years_to_plot:\n",
    "        if year in celebrity_mentions_by_year and len(celebrity_mentions_by_year[year]) > 0:\n",
    "            total_mentions = sum(celebrity_mentions_by_year[year].values())\n",
    "            unique_celebs = len(celebrity_mentions_by_year[year])\n",
    "            print(f\"  {year}: {total_mentions} total mentions, {unique_celebs} unique celebrities\")\n",
    "    \n",
    "    total_overall = sum(celebrity_mentions_overall.values())\n",
    "    unique_overall = len(celebrity_mentions_overall)\n",
    "    print(f\"  All Years: {total_overall} total mentions, {unique_overall} unique celebrities\")\n",
    "\n",
    "# Create the visualizations\n",
    "create_celebrity_mention_plots()\n",
    "\n",
    "print(f\"\\n=== Analysis Complete! ===\")\n",
    "print(f\"Year filtering applied: Celebrities only counted in years they attended\")\n",
    "print(f\"GraphML files saved in '{output_dir}' directory:\")\n",
    "print(f\"- All-years graph: celeb_comentions_all_years.graphml\")\n",
    "for year in unique_years:\n",
    "    if year in year_graphs:\n",
    "        print(f\"- {year} graph: celeb_comentions_{year}.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb801c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# --- Step 1: Load data and create celebrity-year mapping ---\n",
    "celeb_df = pd.read_csv(\"attendees.csv\")  # Replace with your actual filename\n",
    "comments_df = pd.read_csv(\"your_youtube_comments.csv\")  # Replace with your actual filename\n",
    "\n",
    "print(f\"Attendees CSV columns: {list(celeb_df.columns)}\")\n",
    "print(f\"Comments CSV columns: {list(comments_df.columns)}\")\n",
    "\n",
    "# --- Step 2: Text preprocessing function (for celebrity names only) ---\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess celebrity names for better matching with already-preprocessed comments\"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove extra whitespace and normalize\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove common punctuation that might interfere with name matching\n",
    "    text = re.sub(r'[^\\w\\s\\'-]', ' ', text)\n",
    "    \n",
    "    # Handle common variations\n",
    "    text = re.sub(r'\\bkim\\s*k\\b', 'kim kardashian', text)\n",
    "    text = re.sub(r'\\bkardashian\\b', 'kim kardashian', text)  \n",
    "    text = re.sub(r'\\bzendaya\\b', 'zendaya', text)\n",
    "    text = re.sub(r'\\btaylor\\s*swift\\b', 'taylor swift', text)\n",
    "    text = re.sub(r'\\bt\\s*swift\\b', 'taylor swift', text)\n",
    "    text = re.sub(r'\\bbeyonce\\b', 'beyonce', text)\n",
    "    text = re.sub(r'\\bbey\\b', 'beyonce', text)\n",
    "    text = re.sub(r'\\bjlo\\b', 'jennifer lopez', text)\n",
    "    text = re.sub(r'\\bj\\s*lo\\b', 'jennifer lopez', text)\n",
    "    text = re.sub(r'\\bariana\\b', 'ariana grande', text)\n",
    "    text = re.sub(r'\\bari\\b', 'ariana grande', text)\n",
    "    text = re.sub(r'\\bselena\\b', 'selena gomez', text)\n",
    "    text = re.sub(r'\\briri\\b', 'rihanna', text)\n",
    "    text = re.sub(r'\\bgaga\\b', 'lady gaga', text)\n",
    "    text = re.sub(r'\\blady\\s*gaga\\b', 'lady gaga', text)\n",
    "    text = re.sub(r'\\bdua\\b', 'dua lipa', text)\n",
    "    text = re.sub(r'\\bbillie\\b', 'billie eilish', text)\n",
    "    text = re.sub(r'\\bthe\\s*weeknd\\b', 'the weeknd', text)\n",
    "    text = re.sub(r'\\bweeknd\\b', 'the weeknd', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Create mapping of celebrity -> years they attended\n",
    "# Only preprocess celebrity names, comments are already preprocessed\n",
    "celeb_year_mapping = {}\n",
    "for index, row in celeb_df.iterrows():\n",
    "    name = row.get('Name')\n",
    "    year = row.get('Year')  # Attendees CSV uses 'Year' column (capital Y)\n",
    "    \n",
    "    if pd.notna(name) and pd.notna(year):\n",
    "        processed_name = preprocess_text(name)  # Preprocess celebrity name to match preprocessed comments\n",
    "        if processed_name:\n",
    "            if processed_name not in celeb_year_mapping:\n",
    "                celeb_year_mapping[processed_name] = set()\n",
    "            celeb_year_mapping[processed_name].add(year)\n",
    "\n",
    "print(f\"\\nLoaded celebrity attendance data for {len(celeb_year_mapping)} celebrities:\")\n",
    "for celeb, years in list(celeb_year_mapping.items())[:10]:  # Show first 10 as example\n",
    "    print(f\"  {celeb}: {sorted(years)}\")\n",
    "if len(celeb_year_mapping) > 10:\n",
    "    print(f\"  ... and {len(celeb_year_mapping) - 10} more\")\n",
    "\n",
    "# --- Step 3: Setup celebrity patterns (full names only) ---\n",
    "raw_celeb_names = celeb_df['Name'].dropna().unique()\n",
    "\n",
    "# Create mapping system for full names only\n",
    "celeb_name_mapping = {}\n",
    "all_patterns = []\n",
    "\n",
    "for original_name in raw_celeb_names:\n",
    "    processed_name = preprocess_text(original_name)\n",
    "    if not processed_name:\n",
    "        continue\n",
    "    \n",
    "    # Store the canonical name (full name only)\n",
    "    canonical_name = processed_name\n",
    "    \n",
    "    # Add full name pattern only\n",
    "    celeb_name_mapping[processed_name] = canonical_name\n",
    "    all_patterns.append((processed_name, canonical_name, len(processed_name)))\n",
    "\n",
    "# Sort patterns by length (longest first) for better matching\n",
    "all_patterns.sort(key=lambda x: x[2], reverse=True)\n",
    "pattern_strings = [re.escape(pattern[0]) for pattern in all_patterns]\n",
    "\n",
    "celeb_regex = re.compile(r'\\b(?:' + '|'.join(pattern_strings) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "print(f\"Loaded {len(raw_celeb_names)} celebrity names\")\n",
    "print(f\"Created {len(pattern_strings)} search patterns (full names only)\")\n",
    "print(f\"Loaded {len(comments_df)} comments\")\n",
    "\n",
    "# --- Step 4: Create output directory and data collection structures ---\n",
    "output_dir = \"comention_graphs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Data collection structures for plotting\n",
    "celebrity_mentions_by_year = defaultdict(lambda: defaultdict(int))  # {year: {celebrity: count}}\n",
    "celebrity_mentions_overall = defaultdict(int)  # {celebrity: total_count}\n",
    "yearly_totals = defaultdict(int)  # {year: total_mentions}\n",
    "\n",
    "# --- Step 5: Function to extract celebrity mentions with year filtering ---\n",
    "def extract_mentions(text, comment_year):\n",
    "    \"\"\"Extract celebrity mentions from text (text is already preprocessed)\"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return []\n",
    "    \n",
    "    # Text is already preprocessed, use as-is\n",
    "    processed_text = str(text).lower()\n",
    "    \n",
    "    # Find all matches with their positions\n",
    "    matches = []\n",
    "    for match in celeb_regex.finditer(processed_text):\n",
    "        match_text = match.group().lower()\n",
    "        if match_text in celeb_name_mapping:\n",
    "            celebrity_name = celeb_name_mapping[match_text]\n",
    "            \n",
    "            # Only include if celebrity attended in this comment's year\n",
    "            if celebrity_name in celeb_year_mapping and comment_year in celeb_year_mapping[celebrity_name]:\n",
    "                matches.append((match.start(), match.end(), match_text, celebrity_name))\n",
    "    \n",
    "    # Remove overlapping matches (prefer longer matches)\n",
    "    matches.sort(key=lambda x: x[0])\n",
    "    \n",
    "    non_overlapping = []\n",
    "    for i, (start, end, match_text, canonical) in enumerate(matches):\n",
    "        # Check if this match overlaps with any previously accepted match\n",
    "        overlaps = False\n",
    "        for prev_start, prev_end, _, _ in non_overlapping:\n",
    "            if not (end <= prev_start or start >= prev_end):  # They overlap\n",
    "                overlaps = True\n",
    "                break\n",
    "        \n",
    "        if not overlaps:\n",
    "            non_overlapping.append((start, end, match_text, canonical))\n",
    "    \n",
    "    # Extract unique celebrity names (remove duplicates where same person mentioned multiple times)\n",
    "    celebrity_mentions = set()\n",
    "    for _, _, _, canonical in non_overlapping:\n",
    "        celebrity_mentions.add(canonical)\n",
    "    \n",
    "    return list(celebrity_mentions)\n",
    "\n",
    "# --- Step 6: Function to create co-mention graph and collect mention data ---\n",
    "def create_comention_graph(df, year_filter=None, collect_data=False):\n",
    "    \"\"\"Create co-mention graph for celebrities mentioned together and optionally collect mention data\"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Filter by year if specified\n",
    "    if year_filter:\n",
    "        df = df[df['met_gala_year'] == year_filter]\n",
    "        graph_name = f\"Met Gala {year_filter}\"\n",
    "    else:\n",
    "        graph_name = \"All Years\"\n",
    "    \n",
    "    print(f\"\\n=== Processing {graph_name} ===\")\n",
    "    print(f\"Processing {len(df)} comments...\")\n",
    "    \n",
    "    mention_count = 0\n",
    "    total_mentions = 0\n",
    "    \n",
    "    # Process each comment\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract text and year from the comment\n",
    "        comment_text = str(row.get('text', ''))\n",
    "        comment_year = row.get('met_gala_year')  # Extract the comment year!\n",
    "        \n",
    "        if pd.isna(comment_year):\n",
    "            continue\n",
    "        \n",
    "        # Find mentioned celebrities (filtered by year they attended)\n",
    "        mentioned = extract_mentions(comment_text, comment_year)\n",
    "        total_mentions += len(mentioned)\n",
    "        \n",
    "        # Collect data for plotting if requested\n",
    "        if collect_data:\n",
    "            for celebrity in mentioned:\n",
    "                celebrity_mentions_by_year[comment_year][celebrity] += 1\n",
    "                celebrity_mentions_overall[celebrity] += 1\n",
    "                yearly_totals[comment_year] += 1\n",
    "        \n",
    "        if len(mentioned) > 1:\n",
    "            mention_count += 1\n",
    "            # Create edges for all pairs of mentioned celebrities\n",
    "            for celeb1, celeb2 in combinations(sorted(mentioned), 2):\n",
    "                if G.has_edge(celeb1, celeb2):\n",
    "                    G[celeb1][celeb2]['weight'] += 1\n",
    "                else:\n",
    "                    G.add_edge(celeb1, celeb2, weight=1)\n",
    "    \n",
    "    return G, mention_count, total_mentions, graph_name\n",
    "\n",
    "# --- Step 7: Function to analyze graph ---\n",
    "def analyze_comention_graph(G, mention_count, total_mentions, graph_name, df_size):\n",
    "    \"\"\"Analyze and print co-mention graph statistics\"\"\"\n",
    "    print(f\"\\n=== {graph_name} Co-mention Graph Summary ===\")\n",
    "    print(f\"Total comments processed: {df_size}\")\n",
    "    print(f\"Total celebrity mentions: {total_mentions}\")\n",
    "    print(f\"Comments with multiple celebrity mentions: {mention_count}\")\n",
    "    print(f\"Nodes (Celebrities): {G.number_of_nodes()}\")\n",
    "    print(f\"Edges (Co-mentions): {G.number_of_edges()}\")\n",
    "    \n",
    "    if G.number_of_edges() == 0:\n",
    "        print(\"No co-mentions found for this period.\")\n",
    "        return\n",
    "    \n",
    "    # Top co-mentions\n",
    "    print(f\"\\n--- Top 10 Celebrity Co-mentions ({graph_name}) ---\")\n",
    "    edges_with_weights = [(u, v, data['weight']) for u, v, data in G.edges(data=True)]\n",
    "    edges_with_weights.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    for i, (celeb1, celeb2, weight) in enumerate(edges_with_weights[:10]):\n",
    "        print(f\"{i+1}. {celeb1.title()} & {celeb2.title()}: {weight} co-mentions\")\n",
    "    \n",
    "    # Most connected celebrities\n",
    "    print(f\"\\n--- Most Connected Celebrities ({graph_name}) ---\")\n",
    "    if G.number_of_nodes() > 0:\n",
    "        degrees = dict(G.degree())\n",
    "        sorted_degrees = sorted(degrees.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for i, (celeb, degree) in enumerate(sorted_degrees[:10]):\n",
    "            print(f\"{i+1}. {celeb.title()}: {degree} connections\")\n",
    "    \n",
    "    # Additional statistics\n",
    "    if G.number_of_nodes() > 0:\n",
    "        print(f\"\\n--- Network Statistics ({graph_name}) ---\")\n",
    "        print(f\"Average degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\")\n",
    "        \n",
    "        # Most frequently co-mentioned pairs\n",
    "        total_weight = sum([data['weight'] for u, v, data in G.edges(data=True)])\n",
    "        print(f\"Total co-mention instances: {total_weight}\")\n",
    "        \n",
    "        if G.number_of_edges() > 0:\n",
    "            avg_weight = total_weight / G.number_of_edges()\n",
    "            print(f\"Average co-mentions per pair: {avg_weight:.2f}\")\n",
    "\n",
    "# --- Step 8: Function to save graph ---\n",
    "def save_comention_graph(G, graph_name, year_filter=None):\n",
    "    \"\"\"Save co-mention graph as GraphML file\"\"\"\n",
    "    if year_filter:\n",
    "        filename = f\"celeb_comentions_{year_filter}.graphml\"\n",
    "    else:\n",
    "        filename = \"celeb_comentions_all_years.graphml\"\n",
    "    \n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    nx.write_graphml(G, filepath)\n",
    "    print(f\"Saved {graph_name} graph: {filepath}\")\n",
    "\n",
    "# --- Step 9: Create and analyze all-years graph (with data collection) ---\n",
    "G_all, mentions_all, total_mentions_all, name_all = create_comention_graph(comments_df, collect_data=True)\n",
    "analyze_comention_graph(G_all, mentions_all, total_mentions_all, name_all, len(comments_df))\n",
    "save_comention_graph(G_all, name_all)\n",
    "\n",
    "# --- Step 10: Create and analyze individual year graphs ---\n",
    "unique_years = sorted(comments_df['met_gala_year'].dropna().unique())\n",
    "print(f\"\\n=== Found {len(unique_years)} unique years: {unique_years} ===\")\n",
    "\n",
    "year_graphs = {}\n",
    "for year in unique_years:\n",
    "    year_df = comments_df[comments_df['met_gala_year'] == year]\n",
    "    G_year, mentions_year, total_mentions_year, name_year = create_comention_graph(comments_df, year)\n",
    "    \n",
    "    if G_year.number_of_nodes() > 0:  # Only analyze if graph has data\n",
    "        analyze_comention_graph(G_year, mentions_year, total_mentions_year, name_year, len(year_df))\n",
    "        save_comention_graph(G_year, name_year, year)\n",
    "        year_graphs[year] = G_year\n",
    "    else:\n",
    "        print(f\"No co-mentions found for {year}\")\n",
    "\n",
    "# --- Step 11: Cross-year comparison ---\n",
    "print(f\"\\n=== Cross-Year Co-mention Comparison ===\")\n",
    "for year in unique_years:\n",
    "    if year in year_graphs:\n",
    "        G = year_graphs[year]\n",
    "        total_weight = sum([data['weight'] for u, v, data in G.edges(data=True)])\n",
    "        print(f\"{year}: {G.number_of_nodes()} celebrities, {G.number_of_edges()} pairs, {total_weight} total co-mentions\")\n",
    "\n",
    "# --- Step 12: Most mentioned celebrities across all data (with year filtering) ---\n",
    "print(f\"\\n=== Most Mentioned Celebrities (All Years, Year-Filtered) ===\")\n",
    "all_celebrity_mentions = []\n",
    "for index, row in comments_df.iterrows():\n",
    "    comment_text = str(row.get('text', ''))\n",
    "    comment_year = row.get('met_gala_year')\n",
    "    \n",
    "    if pd.notna(comment_year):\n",
    "        mentioned = extract_mentions(comment_text, comment_year)\n",
    "        all_celebrity_mentions.extend(mentioned)\n",
    "\n",
    "if all_celebrity_mentions:\n",
    "    mention_counts = Counter(all_celebrity_mentions)\n",
    "    \n",
    "    for i, (celeb, count) in enumerate(mention_counts.most_common(15)):\n",
    "        # Show which years this celebrity attended\n",
    "        years_attended = sorted(celeb_year_mapping.get(celeb, []))\n",
    "        print(f\"{i+1}. {celeb.title()}: mentioned {count} times (attended: {years_attended})\")\n",
    "else:\n",
    "    print(\"No valid celebrity mentions found after year filtering\")\n",
    "\n",
    "# --- Step 13: Year-specific mention analysis ---\n",
    "print(f\"\\n=== Celebrity Mentions by Year ===\")\n",
    "for year in unique_years:\n",
    "    year_comments = comments_df[comments_df['met_gala_year'] == year]\n",
    "    year_mentions = []\n",
    "    \n",
    "    for index, row in year_comments.iterrows():\n",
    "        comment_text = str(row.get('text', ''))\n",
    "        comment_year = row.get('met_gala_year')\n",
    "        if pd.notna(comment_year):\n",
    "            mentioned = extract_mentions(comment_text, comment_year)\n",
    "            year_mentions.extend(mentioned)\n",
    "    \n",
    "    if year_mentions:\n",
    "        year_counts = Counter(year_mentions)\n",
    "        print(f\"\\n{year} - Top mentioned celebrities:\")\n",
    "        for i, (celeb, count) in enumerate(year_counts.most_common(5)):\n",
    "            print(f\"  {i+1}. {celeb.title()}: {count} mentions\")\n",
    "    else:\n",
    "        print(f\"\\n{year} - No valid celebrity mentions found\")\n",
    "\n",
    "# --- Step 14: Create visualizations ---\n",
    "def create_celebrity_mention_plots():\n",
    "    \"\"\"Create matplotlib plots showing celebrity mention patterns\"\"\"\n",
    "    print(f\"\\n=== Creating Celebrity Mention Visualizations ===\")\n",
    "    \n",
    "    # Set up the plotting style\n",
    "    plt.style.use('default')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Overall top celebrities bar chart\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    top_celebs = dict(Counter(celebrity_mentions_overall).most_common(15))\n",
    "    \n",
    "    celeb_names = [name.title() for name in top_celebs.keys()]\n",
    "    mention_counts = list(top_celebs.values())\n",
    "    \n",
    "    bars = ax1.barh(celeb_names, mention_counts, color=sns.color_palette(\"viridis\", len(celeb_names)))\n",
    "    ax1.set_xlabel('Total Mentions')\n",
    "    ax1.set_title('Top 15 Most Mentioned Celebrities (All Years)', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, count) in enumerate(zip(bars, mention_counts)):\n",
    "        ax1.text(bar.get_width() + max(mention_counts) * 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                str(count), ha='left', va='center', fontweight='bold')\n",
    "    \n",
    "    # 2. Mentions per year line plot\n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    years = sorted(yearly_totals.keys())\n",
    "    total_mentions_per_year = [yearly_totals[year] for year in years]\n",
    "    \n",
    "    ax2.plot(years, total_mentions_per_year, marker='o', linewidth=3, markersize=8, color='red')\n",
    "    ax2.set_xlabel('Year')\n",
    "    ax2.set_ylabel('Total Celebrity Mentions')\n",
    "    ax2.set_title('Celebrity Mentions Over Time', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xticks(years)\n",
    "    \n",
    "    # Add value labels on points\n",
    "    for year, count in zip(years, total_mentions_per_year):\n",
    "        ax2.annotate(str(count), (year, count), textcoords=\"offset points\", \n",
    "                    xytext=(0,10), ha='center', fontweight='bold')\n",
    "    \n",
    "    # 3. Top celebrities by year heatmap\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    \n",
    "    # Get top 10 overall celebrities for heatmap\n",
    "    top_10_celebs = [name for name, _ in Counter(celebrity_mentions_overall).most_common(10)]\n",
    "    \n",
    "    # Create matrix for heatmap\n",
    "    heatmap_data = []\n",
    "    for celeb in top_10_celebs:\n",
    "        celeb_by_year = [celebrity_mentions_by_year[year][celeb] for year in years]\n",
    "        heatmap_data.append(celeb_by_year)\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(heatmap_data, \n",
    "                xticklabels=years,\n",
    "                yticklabels=[name.title() for name in top_10_celebs],\n",
    "                annot=True, \n",
    "                fmt='d', \n",
    "                cmap='YlOrRd',\n",
    "                ax=ax3,\n",
    "                cbar_kws={'label': 'Mentions'})\n",
    "    \n",
    "    ax3.set_title('Top 10 Celebrities Mentions by Year', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Year')\n",
    "    ax3.set_ylabel('Celebrity')\n",
    "    \n",
    "    # 4. Year-over-year growth\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    if len(years) > 1:\n",
    "        growth_rates = []\n",
    "        growth_years = []\n",
    "        for i in range(1, len(years)):\n",
    "            prev_count = yearly_totals[years[i-1]]\n",
    "            curr_count = yearly_totals[years[i]]\n",
    "            if prev_count > 0:\n",
    "                growth_rate = ((curr_count - prev_count) / prev_count) * 100\n",
    "                growth_rates.append(growth_rate)\n",
    "                growth_years.append(f\"{years[i-1]}-{years[i]}\")\n",
    "        \n",
    "        colors = ['green' if rate >= 0 else 'red' for rate in growth_rates]\n",
    "        bars = ax4.bar(growth_years, growth_rates, color=colors, alpha=0.7)\n",
    "        ax4.set_xlabel('Year Transition')\n",
    "        ax4.set_ylabel('Growth Rate (%)')\n",
    "        ax4.set_title('Year-over-Year Growth in Celebrity Mentions', fontsize=14, fontweight='bold')\n",
    "        ax4.grid(axis='y', alpha=0.3)\n",
    "        ax4.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, rate in zip(bars, growth_rates):\n",
    "            height = bar.get_height()\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2., height + (1 if height >= 0 else -3),\n",
    "                    f'{rate:.1f}%', ha='center', va='bottom' if height >= 0 else 'top', fontweight='bold')\n",
    "    \n",
    "    # 5. Celebrity diversity per year (number of unique celebrities mentioned)\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    unique_celebs_per_year = [len(celebrity_mentions_by_year[year]) for year in years]\n",
    "    \n",
    "    ax5.bar(years, unique_celebs_per_year, color='purple', alpha=0.7)\n",
    "    ax5.set_xlabel('Year')\n",
    "    ax5.set_ylabel('Number of Unique Celebrities')\n",
    "    ax5.set_title('Celebrity Diversity by Year', fontsize=14, fontweight='bold')\n",
    "    ax5.grid(axis='y', alpha=0.3)\n",
    "    ax5.set_xticks(years)\n",
    "    \n",
    "    # Add value labels\n",
    "    for year, count in zip(years, unique_celebs_per_year):\n",
    "        ax5.text(year, count + max(unique_celebs_per_year) * 0.01, str(count), \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 6. Distribution of mentions (histogram)\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    mention_counts_list = list(celebrity_mentions_overall.values())\n",
    "    \n",
    "    ax6.hist(mention_counts_list, bins=20, color='orange', alpha=0.7, edgecolor='black')\n",
    "    ax6.set_xlabel('Number of Mentions')\n",
    "    ax6.set_ylabel('Number of Celebrities')\n",
    "    ax6.set_title('Distribution of Celebrity Mention Counts', fontsize=14, fontweight='bold')\n",
    "    ax6.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add statistics text\n",
    "    mean_mentions = sum(mention_counts_list) / len(mention_counts_list)\n",
    "    median_mentions = sorted(mention_counts_list)[len(mention_counts_list)//2]\n",
    "    ax6.axvline(mean_mentions, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_mentions:.1f}')\n",
    "    ax6.axvline(median_mentions, color='blue', linestyle='--', linewidth=2, label=f'Median: {median_mentions}')\n",
    "    ax6.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_path = os.path.join(output_dir, 'celebrity_mentions_analysis.png')\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved celebrity mentions visualization: {plot_path}\")\n",
    "    \n",
    "    # Show summary statistics\n",
    "    print(f\"\\n--- Celebrity Mention Statistics ---\")\n",
    "    print(f\"Total unique celebrities mentioned: {len(celebrity_mentions_overall)}\")\n",
    "    print(f\"Total mentions across all years: {sum(celebrity_mentions_overall.values())}\")\n",
    "    print(f\"Average mentions per celebrity: {mean_mentions:.2f}\")\n",
    "    print(f\"Most mentioned celebrity: {max(celebrity_mentions_overall, key=celebrity_mentions_overall.get).title()} ({max(celebrity_mentions_overall.values())} mentions)\")\n",
    "    print(f\"Years analyzed: {min(years)} - {max(years)}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Create the visualizations\n",
    "create_celebrity_mention_plots()\n",
    "\n",
    "print(f\"\\n=== Analysis Complete! ===\")\n",
    "print(f\"Year filtering applied: Celebrities only counted in years they attended\")\n",
    "print(f\"GraphML files saved in '{output_dir}' directory:\")\n",
    "print(f\"- All-years graph: celeb_comentions_all_years.graphml\")\n",
    "for year in unique_years:\n",
    "    if year in year_graphs:\n",
    "        print(f\"- {year} graph: celeb_comentions_{year}.graphml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
